{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHI Consortium Database - Machine Learning Screening Exercise\n",
    "### Kevin Jaggs Jan 2020\n",
    "\n",
    "### Objective:\n",
    "Using default parameters only, fit a variety of machine learning classifier algorithms to the DHI consortium database. Outcomes will be compiled and ranked by conventional binary classification scoring metrics. This workflow is intended to give a high level overview of which Machine Learning Algorithms present the best opportunities for further detailed investigation.\n",
    "\n",
    "### Method:\n",
    "\n",
    "* Step 1 -  [Import the required python modules](#section_id_import_modules). Import of pandas dataframe, numpy, matplotlib and sklearn modules\n",
    "\n",
    "\n",
    "* Step 2 -  [Import SAAM_Database_csv_to_pandas](#section_id_import_saam_database). Import of dhi consortium database csv file to pandas dataframe. Note: the csv file is an independently formatted file, composed of pg, dhi index adj and user-scored parameters. This format is created ina separate python module.\n",
    "\n",
    "\n",
    "* Step 3 -  [Split dataset into test and train portions](#section_id_test_train_split). For conventional machine learning workflows, the input and output datasets are divided into training and testing sub-volumes. Algorithms are trained on the (not suprisingly) 'train' dataset and model outcomes are compared using the 'test' dataset, to prevent over-fitting.\n",
    "\n",
    "\n",
    "* Step 4 -  [Define classifiers and labels](#section_id_define). Create lists of algoithm labels and sklearn algorithms with basic parameters\n",
    "\n",
    "\n",
    "* Step 5 -  [Feature scale input data](#section_id_feature_scale). Rescale the features/input columns such that they have the properties of a standard normal distribution with a mean of zero and a standard deviation of one.\n",
    "\n",
    "\n",
    "* Step 6 -  [Fit training data](#section_id_algorithm_fit). Iterate through all the selected algorithms and fit the training data. Predict the output of the test data and compare to the actuals. Record accuracy, precision, f1 and AUC scores.\n",
    "\n",
    "\n",
    "* Step 7 - [Display heatmap](#section_id_heatmap) Plot sorted results table - coloured heatmap to show top results in each column\n",
    "\n",
    "\n",
    "\n",
    "### Dataset\n",
    "The SAAM database is a record of over 340 (as of Jan 2021) O&G exploration prospects, each one displaying a DHI signature. This database is part of the DHI consortium, an industry-funded project headed by Rose & Associates  with the objective of creating a methodical, repeatable and technically robust workflow for risk assessment of DHI prospects.  \n",
    "\n",
    "Each prospect is evaluated by scoring over 40 questions related to the DHI characteristics, data quality, potential pitfalls and modelling results.\n",
    "\n",
    "This is a binary classification exercise as the final ouput of the dataset is denoted by 0 for failure cases, and 1 for success cases. \n",
    "\n",
    "Options to include Pg and Adj DhiIndex in the evaluations, but this should be regarded as data leakage, partivularly in the case of DHI index Adj.\n",
    "\n",
    "### Programming\n",
    "This evaluation is performed using Python code and SKlearn provides all the classifier modules. \n",
    "\n",
    "### Outputs\n",
    "Overview plot of model fit for each classifier\n",
    "Sheet of evaluation criteria ordered by descending AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id_import_modules'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import required Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "#pandas dataframe - similar to a python version of excel. Most efficient way to perform data operations\n",
    "import pandas as pd\n",
    "\n",
    "#numpy for most mathematical operations\n",
    "import numpy as np\n",
    "\n",
    "#matplotlib for plotting functions\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.colors import ListedColormap\n",
    "#seaborn for plotting heatmap\n",
    "#import seaborn as sns\n",
    "\n",
    "#sklearn for machine learning modules and scoring algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, f1_score, plot_confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id_import_saam_database'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import SAAM Database csv file to pandas\n",
    "The csv file is imported into a pandas dataframe, allowing ease of computation in later modules. All columns are considered numeric. The column header is the data category and the index is the prospect name. All undrilled prospects have been removed from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size on import\n",
      "Number of prospects : 352\n",
      "Number of data categories : 43\n"
     ]
    }
   ],
   "source": [
    "def readcsvfile():\n",
    "    '''\n",
    "    (csv)->(pandas dataframe)\n",
    "    routine to read import csv file to pandas\n",
    "    comma separation, column headers = first row of text\n",
    "    All column data is considered numeric\n",
    "    Index = prospect name/ID\n",
    "    -999.25 values are converted to numpy NaN\n",
    "    PRECONDITION: Import csv file is the correct format. All prospects without a 1/0 output removed.\n",
    "    KJAGGS June 2020\n",
    "    '''\n",
    "    \n",
    "    #read csv file to pandas dataframe\n",
    "    df = pd.read_csv('saam_v26b_cat.csv', encoding = 'utf-8',header=0,sep=',')\n",
    "    df = df.set_index('Prospect/ zone: ')\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df = df.replace(-999.25,np.NaN)\n",
    "    df = df.replace(np.NaN,0)\n",
    "    #print(df.isnull().any())\n",
    "    return df\n",
    "\n",
    "df_saam = readcsvfile()\n",
    "\n",
    "###optional qc features - remove hash/# to view \n",
    "#print(df_saam.head)\n",
    "#print(df_saam.columns.tolist)\n",
    "\n",
    "\n",
    "print(\"Dataframe size on import\")\n",
    "print(\"Number of prospects :\", df_saam.shape[0])\n",
    "print(\"Number of data categories :\", df_saam.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id_test_train_split'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split into test and train datasets\n",
    "Data is divided into test and training sub-volumes for the purpose of fitting models and preventing over-fitting/bias issues. The current defaults in the module below are to split 80:20 train:test. No random number seeding, no shuffling of input data and no stratifying (equal proportions of success/fail  outcomes in each sub-volume). These faetures are adjusted at the bottom of the next cell as the input to function; user can change accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test dataset sizes\n",
      "Training dataset size : (264, 40)\n",
      "Test dataset size : (88, 40)\n"
     ]
    }
   ],
   "source": [
    "def training_split(Xdata, Ydata, test_size=0.2,stratify=None,random_state=None,shuffle=False):\n",
    "    '''\n",
    "    (DataframeXColumns)(DataframeYColumn)=>(array)(array)(array)(array)\n",
    "    For the purposes of splitting x and y data into test and training sets\n",
    "    train_test_split is currently set to default settings\n",
    "    PRECONDITION: Input datasets are formatted correctly\n",
    "    KJAGGS June2020\n",
    "    '''\n",
    "\n",
    "    #split the data - default settings for now\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata, test_size=test_size,stratify=stratify, random_state = random_state, shuffle = shuffle)\n",
    "\n",
    "    #resize the output data sets if a 1 column vector, now compatible  with regression modules\n",
    "    if len(X_train.shape) <2:  \n",
    "       X_train = X_train.ravel()\n",
    "    if len(y_train.shape) <2:  \n",
    "       y_train = y_train.ravel()\n",
    "    if len(X_test.shape) <2:  \n",
    "       X_test = X_test.ravel()\n",
    "    if len(y_train.shape) <2:  \n",
    "       y_test = y_test.ravel()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#output dataset is success/fail only\n",
    "y = df_saam['Success or Fail']\n",
    "\n",
    "X = df_saam\n",
    "\n",
    "#remove result column from input dataset\n",
    "#option to keep pg and dhi index adjusted in training dataset just change the # between the two lines below to make the change\n",
    "\n",
    "#X.drop(['Success or Fail'], axis=1, inplace=True)\n",
    "X.drop(['Success or Fail','DHI Index after data adjustment','Pg'], axis=1, inplace=True)\n",
    "#X = df_saam[['DHI Index after data adjustment','Pg']]\n",
    "\n",
    "#split the datasets\n",
    "#Shuffle = randomly shuffle the data before, If shuffle=False then stratify must be None.\n",
    "#random state = seeding of random numbers for reproducibility across various modules\n",
    "#stratify = ensure proportion of outcomes are the same across both datasets i.e % of successes in train = % of successes in test\n",
    "X_train, X_test, y_train, y_test = training_split(X,y,shuffle=True,random_state=100,stratify=y,test_size=0.25)\n",
    "\n",
    "print(\"Train and test dataset sizes\")\n",
    "print(\"Training dataset size :\", X_train.shape)\n",
    "print(\"Test dataset size :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id_define'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define classifiers and labels\n",
    "Create 2 python lists; one for a ml algorithm label, and the other with the SKlearn module ID + basic parameters. The model fit section will iterate through these lists a fit the train data to the chosen algorithm, it will also validate the model using the test dataset. Users can change the parameters withom the brackets. User manuals can be found at the following link: \n",
    "https://scikit-learn.org/stable/user_guide.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test label to id the current process/algorithm in the iteration sequwence\n",
    "clf_names = [\"Logisitic\",\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "#list of classifier modules and basic parameter selection \n",
    "#iterate in conjunction with the list above\n",
    "classifiers = [\n",
    "    linear_model.LogisticRegression(),\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(kernel=\"linear\"),\n",
    "    SVC(gamma=0.01, C=10),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=40),\n",
    "    RandomForestClassifier(max_depth=20, n_estimators=20, max_features=X_train_scaled.shape[1]),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id_feature_scale'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature scale the input data\n",
    "Input independent variables are scaled so that the the attribute mean is zero with a unit standard deviation. Gradient descent algorithms (neural networks, for example) run more efficiently if input tfeatures are scaled accordingly. decision tree methods are invariant to scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up scaler - StandardScaler from SciKit learn\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "#z = (x - u) / s\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#scaler is calculated on the train data ONLY. Would be considered data leakage - test data must not influence the model output.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "#apply the scaler to the train and test datasets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id_algorithm_fit'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fit data using algorithms\n",
    "Iterate through all the selected algorithms and fit the training data. Predict the output of the test data and compare to the actuals. Record accuracy, precision, f1 and AUC scores. Final results output to a pandas dataframe, sorted on AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kxj17699\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "#create empty dataframe to receive model scores\n",
    "df_alg = pd.DataFrame(index=range(len(clf_names)),columns=range(4))\n",
    "\n",
    "#column names for the results pandas dataframe\n",
    "df_alg.columns=['Accuracy','Precision','Weighted F1','AUC']\n",
    "#index names for the results pandas dataframe\n",
    "df_alg.index=clf_names\n",
    "\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(clf_names, classifiers):\n",
    "\n",
    "    #fit the data to the current classifier\n",
    "    clf.fit(X_train_scaled, y_train)   \n",
    "    y_predict = clf.predict(X_test_scaled)\n",
    "    \n",
    "    df_alg.loc[name,'Accuracy'] = accuracy_score(y_test, y_predict)\n",
    "    df_alg.loc[name,'Precision'] = precision_score(y_test, y_predict)\n",
    "    df_alg.loc[name,'Weighted F1'] = f1_score(y_test, y_predict, average='weighted')\n",
    "    df_alg.loc[name,'AUC'] = roc_auc_score(y_test, y_predict)\n",
    "\n",
    "    #print(name , \"default parameters\")\n",
    "    #print(\"Accuracy =\", score)\n",
    "    #print(\"Precision =\", precision_score(y_test, y_predict))\n",
    "    #print('Weighted f1 = {:.2f}'.format(f1_score(y_test, y_predict, average='weighted')))\n",
    "    #print(\"AUC =\", roc_auc_score(y_test, y_predict))\n",
    "    #print(\"\\n\")\n",
    "    #print(classification_report(y_test, y_tuned_predict))\n",
    "\n",
    "#sort final dataframe by AUC descending \n",
    "df_alg.sort_values(['AUC'], ascending=[False], inplace=True)   \n",
    "#convert string entries to float\n",
    "df_alg = df_alg.apply(pd.to_numeric, errors='ignore')\n",
    "#round to 3 decimal places\n",
    "df_alg = df_alg.round(decimals=3)    \n",
    "#print(df_alg)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id_heatmap'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Display final results \n",
    "Pandas dataframe is given a gradient fill to highlight the best performing alogirthm for each scoring metric. Dark blue = high score, light purple = low score.\n",
    "NOTE: Use the >| Run button if colour map is not displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_afd63124_5202_11eb_9b08_e09d31ec7894row0_col0 {\n",
       "            background-color:  #023858;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row0_col1 {\n",
       "            background-color:  #023858;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row0_col2 {\n",
       "            background-color:  #023858;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row0_col3 {\n",
       "            background-color:  #023858;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row1_col0 {\n",
       "            background-color:  #034e7b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row1_col1 {\n",
       "            background-color:  #034369;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row1_col2 {\n",
       "            background-color:  #03476f;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row1_col3 {\n",
       "            background-color:  #045280;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row2_col0 {\n",
       "            background-color:  #034e7b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row2_col1 {\n",
       "            background-color:  #034f7d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row2_col2 {\n",
       "            background-color:  #034871;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row2_col3 {\n",
       "            background-color:  #045788;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row3_col0 {\n",
       "            background-color:  #045a8d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row3_col1 {\n",
       "            background-color:  #034a74;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row3_col2 {\n",
       "            background-color:  #034e7b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row3_col3 {\n",
       "            background-color:  #045d92;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row4_col0 {\n",
       "            background-color:  #045a8d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row4_col1 {\n",
       "            background-color:  #045382;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row4_col2 {\n",
       "            background-color:  #034f7d;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row4_col3 {\n",
       "            background-color:  #046096;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row5_col0 {\n",
       "            background-color:  #046299;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row5_col1 {\n",
       "            background-color:  #034e7b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row5_col2 {\n",
       "            background-color:  #045788;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row5_col3 {\n",
       "            background-color:  #05659f;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row6_col0 {\n",
       "            background-color:  #046299;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row6_col1 {\n",
       "            background-color:  #045280;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row6_col2 {\n",
       "            background-color:  #045788;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row6_col3 {\n",
       "            background-color:  #0567a1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row7_col0 {\n",
       "            background-color:  #0569a4;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row7_col1 {\n",
       "            background-color:  #04598c;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row7_col2 {\n",
       "            background-color:  #045d92;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row7_col3 {\n",
       "            background-color:  #056faf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row8_col0 {\n",
       "            background-color:  #75a9cf;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row8_col1 {\n",
       "            background-color:  #0569a4;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row8_col2 {\n",
       "            background-color:  #2987bc;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row8_col3 {\n",
       "            background-color:  #84b0d3;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row9_col0 {\n",
       "            background-color:  #f9f2f8;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row9_col1 {\n",
       "            background-color:  #f1ebf4;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row9_col2 {\n",
       "            background-color:  #fdf5fa;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row9_col3 {\n",
       "            background-color:  #f8f1f8;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row10_col0 {\n",
       "            background-color:  #fff7fb;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row10_col1 {\n",
       "            background-color:  #fff7fb;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row10_col2 {\n",
       "            background-color:  #fff7fb;\n",
       "            color:  #000000;\n",
       "        }    #T_afd63124_5202_11eb_9b08_e09d31ec7894row10_col3 {\n",
       "            background-color:  #fff7fb;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >Precision</th>        <th class=\"col_heading level0 col2\" >Weighted F1</th>        <th class=\"col_heading level0 col3\" >AUC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row0\" class=\"row_heading level0 row0\" >Random Forest</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row0_col0\" class=\"data row0 col0\" >0.705000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row0_col1\" class=\"data row0 col1\" >0.733000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row0_col2\" class=\"data row0 col2\" >0.705000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row0_col3\" class=\"data row0 col3\" >0.705000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row1\" class=\"row_heading level0 row1\" >Linear SVM</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row1_col0\" class=\"data row1 col0\" >0.682000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row1_col1\" class=\"data row1 col1\" >0.711000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row1_col2\" class=\"data row1 col2\" >0.682000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row1_col3\" class=\"data row1 col3\" >0.682000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row2\" class=\"row_heading level0 row2\" >Gaussian Process</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row2_col0\" class=\"data row2 col0\" >0.682000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row2_col1\" class=\"data row2 col1\" >0.686000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row2_col2\" class=\"data row2 col2\" >0.680000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row2_col3\" class=\"data row2 col3\" >0.677000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row3\" class=\"row_heading level0 row3\" >Neural Net</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row3_col0\" class=\"data row3 col0\" >0.670000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row3_col1\" class=\"data row3 col1\" >0.696000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row3_col2\" class=\"data row3 col2\" >0.671000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row3_col3\" class=\"data row3 col3\" >0.670000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row4\" class=\"row_heading level0 row4\" >AdaBoost</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row4_col0\" class=\"data row4 col0\" >0.670000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row4_col1\" class=\"data row4 col1\" >0.680000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row4_col2\" class=\"data row4 col2\" >0.669000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row4_col3\" class=\"data row4 col3\" >0.667000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row5\" class=\"row_heading level0 row5\" >Decision Tree</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row5_col0\" class=\"data row5 col0\" >0.659000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row5_col1\" class=\"data row5 col1\" >0.689000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row5_col2\" class=\"data row5 col2\" >0.659000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row5_col3\" class=\"data row5 col3\" >0.659000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row6\" class=\"row_heading level0 row6\" >RBF SVM</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row6_col0\" class=\"data row6 col0\" >0.659000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row6_col1\" class=\"data row6 col1\" >0.681000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row6_col2\" class=\"data row6 col2\" >0.659000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row6_col3\" class=\"data row6 col3\" >0.657000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row7\" class=\"row_heading level0 row7\" >Logisitic</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row7_col0\" class=\"data row7 col0\" >0.648000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row7_col1\" class=\"data row7 col1\" >0.667000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row7_col2\" class=\"data row7 col2\" >0.647000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row7_col3\" class=\"data row7 col3\" >0.645000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row8\" class=\"row_heading level0 row8\" >Nearest Neighbors</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row8_col0\" class=\"data row8 col0\" >0.568000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row8_col1\" class=\"data row8 col1\" >0.622000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row8_col2\" class=\"data row8 col2\" >0.566000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row8_col3\" class=\"data row8 col3\" >0.574000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row9\" class=\"row_heading level0 row9\" >QDA</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row9_col0\" class=\"data row9 col0\" >0.443000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row9_col1\" class=\"data row9 col1\" >0.250000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row9_col2\" class=\"data row9 col2\" >0.304000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row9_col3\" class=\"data row9 col3\" >0.474000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894level0_row10\" class=\"row_heading level0 row10\" >Naive Bayes</th>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row10_col0\" class=\"data row10 col0\" >0.432000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row10_col1\" class=\"data row10 col1\" >0.200000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row10_col2\" class=\"data row10 col2\" >0.299000</td>\n",
       "                        <td id=\"T_afd63124_5202_11eb_9b08_e09d31ec7894row10_col3\" class=\"data row10 col3\" >0.462000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b7c3443a08>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alg.style.background_gradient(cmap='PuBu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
